import sys
import os
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append('/home/chenzc/cvd/model_blip')
sys.path.append('/home/chenzc/cvd/model_blip/evaluate')

import re
import json
from typing import List, Dict, Tuple, Optional, Callable, Union
import numpy as np
import pandas as pd
import nltk
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
from nltk.translate.meteor_score import meteor_score
from rouge_score import rouge_scorer
from pycocoevalcap.cider.cider import Cider
import sacrebleu
import logging
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision.utils import save_image
from PIL import Image
from torch.utils.data import DataLoader

# ä½¿ç”¨ HuggingFace transformers - BLIP
from transformers import BlipProcessor, BlipForConditionalGeneration, AutoProcessor
# kosmos
from transformers import AutoProcessor, AutoModelForVision2Seq

# å¯¼å…¥æ‚¨çš„æ•°æ®é›†
from data.datasets_loader_evaluator import VisualGenomeDataset, RefCOCOPlusDataset

from model_blip.inference import AlphaBlipInference

class BLIPCaptioner:
    """ä½¿ç”¨ HuggingFace BLIP æ¨¡å‹çš„å›¾åƒæè¿°ç”Ÿæˆå™¨"""
    
    def __init__(self, model_name="Salesforce/blip-image-captioning-base", device=None):
        """
        åˆå§‹åŒ– BLIP æ¨¡å‹
        
        Args:
            model_name: HuggingFace BLIP æ¨¡å‹åç§°
            device: è®¾å¤‡ (cuda/cpu)ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨é€‰æ‹©
        """

        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        self.processor = BlipProcessor.from_pretrained(model_name)
        self.model = BlipForConditionalGeneration.from_pretrained(
            model_name,
            torch_dtype=torch.float32
        )
        
        self.model.to(self.device)
        self.model.eval()
    

    def inference(self, image, max_length=20, num_beams=3):
        """
        å¯¹å›¾åƒç”Ÿæˆæè¿°
        
        Args:
            image: PIL Image
            max_length: ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦
            num_beams: beam searchçš„beamæ•°é‡
            
        Returns:
            str: ç”Ÿæˆçš„æ–‡æœ¬
        """
        try:
            # å¤„ç†è¾“å…¥ - åªä¼ å…¥å›¾åƒï¼Œä¸ä½¿ç”¨æ–‡æœ¬prompt
            inputs = self.processor(image, return_tensors="pt")
            
            # å°†è¾“å…¥ç§»åˆ°æ­£ç¡®çš„è®¾å¤‡
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ç”Ÿæˆæ–‡æœ¬ - åªä½¿ç”¨beam search
            with torch.no_grad():
                generated_ids = self.model.generate(
                    **inputs,
                    max_length=max_length,
                    num_beams=num_beams,
                    early_stopping=True,
                )
            
            # è§£ç ç”Ÿæˆçš„æ–‡æœ¬
            generated_text = self.processor.decode(generated_ids[0], skip_special_tokens=True)
            
            return generated_text.strip()
            
        except Exception as e:
            print(f"æ¨ç†å‡ºé”™: {e}")
            return ""
    
class Kosmos2:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = AutoModelForVision2Seq.from_pretrained("microsoft/kosmos-2-patch14-224")
        self.processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
        self.model.to(self.device)
        self.model.eval()  
    
    def inference(self, image, bbox, prompt="<grounding>What is<phrase> this object</phrase>?"):
        inputs = self.processor(
            text=prompt, 
            images=image, 
            bboxes=bbox,
            return_tensors="pt"
        )
        
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        with torch.no_grad():  
            generated_ids = self.model.generate(
                pixel_values=inputs["pixel_values"],
                input_ids=inputs["input_ids"],
                attention_mask=inputs["attention_mask"],
                image_embeds=None,
                image_embeds_position_mask=inputs["image_embeds_position_mask"],
                use_cache=True,
                max_new_tokens=128,
            )
        
        generated_text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
        processed_text = self.processor.post_process_generation(generated_text)
        
        return processed_text


nltk.download('punkt', quiet=True)
nltk.download('wordnet', quiet=True)

class TextMetrics:
    """æ–‡æœ¬è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ–‡æœ¬æŒ‡æ ‡è®¡ç®—å™¨"""
        self.rouge_scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)
        self.cider_scorer = Cider()
        self.smoothing = SmoothingFunction().method1 
    
    def preprocess_text(self, text: str) -> str:
        if not isinstance(text, str):
            text = str(text)
        text = text.lower()
        text = re.sub(r'\s+', ' ', text).strip()
        return text
    
    def tokenize(self, text: str) -> List[str]:
        text = self.preprocess_text(text)
        tokens = text.split()
        return tokens
    
    def compute_bleu(self, predictions: List[str], references: List[List[str]]) -> Dict:
        refs_transposed = []
        max_refs = max(len(refs) for refs in references) if references else 1
        
        for i in range(max_refs):
            ref_list = [refs[i] if i < len(refs) else refs[0] for refs in references]
            refs_transposed.append(ref_list)
        
        bleu = sacrebleu.corpus_bleu(predictions, refs_transposed)
        
        return {
            'BLEU-1': bleu.precisions[0],
            'BLEU-2': bleu.precisions[1], 
            'BLEU-3': bleu.precisions[2],
            'BLEU-4': bleu.score,
        }
    
    def compute_meteor(self, predictions: List[str], references: List[List[str]]) -> float:
        meteor_scores = []
        
        for pred, refs in zip(predictions, references):
            pred_tokens = self.tokenize(pred)
            
            ref_scores = []
            for ref in refs:
                ref_tokens = self.tokenize(ref)
                score = meteor_score([ref_tokens], pred_tokens)
                ref_scores.append(score)
             
            meteor_scores.append(max(ref_scores) if ref_scores else 0.0)
        
        return np.mean(meteor_scores)
    
    def compute_rouge_l(self, predictions: List[str], references: List[List[str]]) -> float:
        """è®¡ç®—ROUGE-Låˆ†æ•°"""
        rouge_scores = []
        
        for pred, refs in zip(predictions, references):
            pred_clean = self.preprocess_text(pred)
            
            ref_scores = []
            for ref in refs:
                ref_clean = self.preprocess_text(ref)
                scores = self.rouge_scorer.score(ref_clean, pred_clean)
                ref_scores.append(scores['rougeL'].fmeasure)
            rouge_scores.append(max(ref_scores) if ref_scores else 0.0)
        
        return np.mean(rouge_scores)
    
    def compute_cider(self, predictions: List[str], references: List[List[str]]) -> float:
        gts = {}
        res = {}
        
        for i, (pred, refs) in enumerate(zip(predictions, references)):
            pred_clean = self.preprocess_text(pred)
            refs_clean = [self.preprocess_text(ref) for ref in refs]
            
            gts[i] = refs_clean
            res[i] = [pred_clean]
        
        score, scores = self.cider_scorer.compute_score(gts, res)
        return score

class ModelComparisionEvaluator:
    def __init__(self, config):
        self.config = config
        
        # åˆå§‹åŒ–æ ‡å‡† BLIP æ¨¡å‹
        self.blip_caption = BLIPCaptioner(
            model_name=getattr(config, 'base_model', "Salesforce/blip-image-captioning-base"),
            device=getattr(config, 'device', None)
        )
        
        self.alpha_blip_caption = AlphaBlipInference(
            checkpoint_path=getattr(config, 'checkpoint_path', None))   
 
        # åˆå§‹åŒ–Kosmos2æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼‰
        self.kosmos2 = None
        if getattr(config, 'use_kosmos2', False):
            try:
                self.kosmos2 = Kosmos2()
                print("âœ… Kosmos2 æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                print(f"âŒ åŠ è½½ Kosmos2 æ¨¡å‹å¤±è´¥: {e}")
        
        self.metrics = TextMetrics()
        
        # å®šä¹‰æ¯ä¸ªæ¨¡å‹ä½¿ç”¨çš„maskç±»å‹
        self.model_mask_config = getattr(config, 'model_mask_config', {
            'blip': {
                'VisualGenome': None,  # BLIPä¸ä½¿ç”¨maskï¼Œåªç”¨åŸå›¾
                'RefCOCOPlus': None
            },
            'alphablip': {
                'VisualGenome': 'ellipse_mask',  # AlphaBlipåœ¨VGä¸Šä½¿ç”¨ellipse_mask
                'RefCOCOPlus': 'gray_mask'       # AlphaBlipåœ¨RefCOCO+ä¸Šä½¿ç”¨gray_mask
            }
        })
        
        # å¦‚æœé…ç½®ä¸­åŒ…å«Kosmos2ï¼Œæ·»åŠ åˆ°æ¨¡å‹é…ç½®ä¸­
        if self.kosmos2:
            if 'kosmos2' not in self.model_mask_config:
                self.model_mask_config['kosmos2'] = {
                    'VisualGenome': None,  # Kosmos2ä½¿ç”¨bboxä¿¡æ¯ï¼Œä¸éœ€è¦mask
                    'RefCOCOPlus': None
                }

        self.samples = {}
        self.texts = {}
        self.predictions = {}
        self.results = {}

    def load_datasets(self):
        """åŠ è½½æ•°æ®é›†"""
        datasets = {}
        
        try:
            vg_dataset = VisualGenomeDataset(
                region_descriptions_file=self.config.vg_region_descriptions_file,
                image_data_file=self.config.vg_image_data_file,
                images_dir=self.config.vg_images_dir,
                image_size=(384, 384)
            )
            datasets['VisualGenome'] = vg_dataset
            print(f"âœ… VisualGenome æ•°æ®é›†åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ åŠ è½½ VisualGenome æ•°æ®é›†å¤±è´¥: {e}")
        
        try:
            refcoco_dataset = RefCOCOPlusDataset(
                refs_file=self.config.refs_file,
                instances_file=self.config.instances_file,
                images_dir=self.config.images_dir,
                image_size=(384, 384)
            )
            datasets['RefCOCOPlus'] = refcoco_dataset
            print(f"âœ… RefCOCOPlus æ•°æ®é›†åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ åŠ è½½ RefCOCOPlus æ•°æ®é›†å¤±è´¥: {e}")
        
        return datasets
    
    def extract_samples_from_dataset(self, dataset, dataset_name):
        """ä»æ•°æ®é›†ä¸­æå–æ ·æœ¬ - ä¿å­˜æ‰€æœ‰å¯ç”¨çš„maskç±»å‹"""
        samples = []
        texts = []
        
        total_samples = len(dataset)
        
        # è·å–æœ€å¤§æ ·æœ¬æ•°é™åˆ¶
        max_samples = getattr(self.config, 'max_samples_per_dataset', None)
        
        # å¦‚æœè®¾ç½®äº†é‡‡æ ·é™åˆ¶ï¼Œåˆ™éšæœºé‡‡æ ·
        if max_samples is not None and total_samples > max_samples:
            print(f"ğŸ“Š {dataset_name} æ•°æ®é›†æ€»æ ·æœ¬æ•°: {total_samples}, éšæœºé‡‡æ ·: {max_samples} ä¸ª")
            import random
            random.seed(42)  # è®¾ç½®éšæœºç§å­ä¿è¯å¯é‡å¤æ€§
            sample_indices = random.sample(range(total_samples), max_samples)
            sample_indices.sort()  # æ’åºä»¥ä¿æŒæŸç§é¡ºåº
        else:
            print(f"ğŸ“Š {dataset_name} æ•°æ®é›†ä½¿ç”¨å…¨éƒ¨æ ·æœ¬: {total_samples} ä¸ª")
            sample_indices = range(total_samples)
        
        for idx, i in enumerate(sample_indices):
            try:
                sample = dataset[i]
                text = sample["text"]
                
                if isinstance(text, list):
                    text = text[0] if text else ""
                
                texts.append(text)
                
                # ä¿å­˜åŸå§‹æ ·æœ¬å’Œæ‰€æœ‰å¯ç”¨çš„mask
                sample_data = {
                    'index': i,
                    'sample_idx': idx,  # é‡‡æ ·åçš„ç´¢å¼•
                    'orig_image': sample['orig_image'],
                    'text': text,
                    'dataset_name': dataset_name,
                    'original_sample': sample
                }
                
                # æ ¹æ®æ•°æ®é›†ç±»å‹ä¿å­˜æ‰€æœ‰å¯ç”¨çš„maskå’Œå…¶ä»–ä¿¡æ¯
                if dataset_name == "VisualGenome":
                    sample_data['available_masks'] = {
                        'bbox_mask': sample.get('bbox_mask', None),
                        'ellipse_mask': sample.get('ellipse_mask', None)
                    }
                    # ä¿å­˜bboxä¿¡æ¯ï¼ˆç”¨äºKosmos2ç­‰éœ€è¦bboxçš„æ¨¡å‹ï¼‰
                    sample_data['bbox'] = sample.get('normalized_bbox', None)
                    
                elif dataset_name == "RefCOCOPlus":
                    sample_data['available_masks'] = {
                        'binary_mask': sample.get('binary_mask', None),
                        'gray_mask': sample.get('gray_mask', None)
                    }
                    # ä¿å­˜bboxä¿¡æ¯ï¼ˆç”¨äºKosmos2ç­‰éœ€è¦bboxçš„æ¨¡å‹ï¼‰
                    sample_data['bbox'] = sample.get('normalized_bbox', None)
                
                samples.append(sample_data)
                    
            except Exception as e:
                print(f"  âš ï¸  å¤„ç†æ ·æœ¬ {i} æ—¶å‡ºé”™: {e}")
                continue
        
        print(f"âœ… {dataset_name} æ•°æ®é›†æˆåŠŸæå–: {len(samples)} ä¸ªæ ·æœ¬")
        return samples, texts

    def get_mask_for_model(self, sample, model_name, dataset_name):
        """æ ¹æ®æ¨¡å‹å’Œæ•°æ®é›†è·å–å¯¹åº”çš„mask"""
        if model_name not in self.model_mask_config:
            return None
        
        mask_type = self.model_mask_config[model_name].get(dataset_name, None)
        
        if mask_type is None:
            return None
        
        available_masks = sample.get('available_masks', {})
        return available_masks.get(mask_type, None)

    def load_and_extract_datasets(self):
        """åŠ è½½æ•°æ®é›†å¹¶æå–æ ·æœ¬"""
        datasets = self.load_datasets()
        
        if not datasets:
            return
        
        for dataset_name, dataset in datasets.items():
            try:
                samples, texts = self.extract_samples_from_dataset(dataset, dataset_name)
                
                if samples:
                    self.samples[dataset_name] = samples
                    self.texts[dataset_name] = texts
                
            except Exception as e:
                continue

    def run_inference_for_dataset(self, dataset_name):
        """ä¸ºå•ä¸ªæ•°æ®é›†è¿è¡Œæ¨ç†"""
        if dataset_name not in self.samples:
            return
        
        samples = self.samples[dataset_name]
        
        # åˆå§‹åŒ–é¢„æµ‹ç»“æœå­—å…¸
        predictions_dict = {}
        
        print(f"\nğŸš€ å¼€å§‹å¯¹ {dataset_name} æ•°æ®é›†è¿›è¡Œæ¨ç†...")
        print(f"æ€»æ ·æœ¬æ•°: {len(samples)}")
        
        # æ‰“å°æ¨¡å‹é…ç½®ä¿¡æ¯
        print(f"ğŸ“‹ æ¨¡å‹é…ç½®:")
        for model_name, dataset_config in self.model_mask_config.items():
            mask_type = dataset_config.get(dataset_name, None)
            mask_info = f"ä½¿ç”¨ {mask_type}" if mask_type else "ä¸ä½¿ç”¨mask(ä»…åŸå›¾)"
            print(f"  - {model_name}: {mask_info}")

        for idx, sample in enumerate(samples):
            try:
                orig_image = sample['orig_image']
                
                # æ ‡å‡†BLIPæ¨ç†
                if 'blip' in self.model_mask_config:
                    if 'blip' not in predictions_dict:
                        predictions_dict['blip'] = []
                    
                    blip_pred = self.blip_caption.inference(
                        orig_image,
                        max_length=getattr(self.config, 'max_length', 50),
                        num_beams=getattr(self.config, 'num_beams', 5)
                    )
                    predictions_dict['blip'].append(blip_pred)
                
                # AlphaBlipæ¨ç†
                if 'alphablip' in self.model_mask_config and self.alpha_blip_caption:
                    if 'alphablip' not in predictions_dict:
                        predictions_dict['alphablip'] = []
                    
                    alpha_blip_mask = self.get_mask_for_model(sample, 'alphablip', dataset_name)
                    alpha_blip_pred = self.alpha_blip_caption.generate_caption(
                        orig_image,
                        mask_image=alpha_blip_mask,
                        max_length=getattr(self.config, 'max_length', 20),
                        num_beams=getattr(self.config, 'num_beams', 3)
                    )
                    predictions_dict['alphablip'].append(alpha_blip_pred)
                
                # Kosmos2æ¨ç†
                if 'kosmos2' in self.model_mask_config and self.kosmos2:
                    if 'kosmos2' not in predictions_dict:
                        predictions_dict['kosmos2'] = []
                    
                    bbox = sample.get('bbox', None)
                    if bbox:
                        kosmos2_pred = self.kosmos2.inference(orig_image, bbox)
                        predictions_dict['kosmos2'].append(kosmos2_pred)
                    else:
                        predictions_dict['kosmos2'].append("")
                
                # æ¯100ä¸ªæ ·æœ¬æ‰“å°ä¸€æ¬¡è¿›åº¦
                if (idx + 1) % 100 == 0:
                    print(f"  å·²å¤„ç†: {idx + 1}/{len(samples)} æ ·æœ¬")
                    
            except Exception as e:
                print(f"  âš ï¸  æ¨ç†æ ·æœ¬ {idx} æ—¶å‡ºé”™: {e}")
                # ä¸ºæ‰€æœ‰æ¨¡å‹æ·»åŠ ç©ºé¢„æµ‹
                for model_name in self.model_mask_config.keys():
                    if model_name == 'blip' or \
                       (model_name == 'alphablip' and self.alpha_blip_caption) or \
                       (model_name == 'kosmos2' and self.kosmos2):
                        if model_name not in predictions_dict:
                            predictions_dict[model_name] = []
                        predictions_dict[model_name].append("")
                continue
        
        # å­˜å‚¨é¢„æµ‹ç»“æœ
        self.predictions[dataset_name] = predictions_dict
        
        print(f"âœ… {dataset_name} æ¨ç†å®Œæˆï¼")

    def run_evaluation(self):
        """è¿è¡Œå®Œæ•´çš„è¯„ä¼°æµç¨‹"""
        print("ğŸ”„ å¼€å§‹è¯„ä¼°æµç¨‹...")
        
        # æ‰“å°æ¨¡å‹maské…ç½®
        print("\nğŸ¯ æ¨¡å‹Maské…ç½®:")
        for model_name, dataset_configs in self.model_mask_config.items():
            print(f"  {model_name}:")
            for dataset_name, mask_type in dataset_configs.items():
                mask_info = mask_type if mask_type else "æ— mask(ä»…åŸå›¾)"
                print(f"    - {dataset_name}: {mask_info}")
        
        # åŠ è½½æ•°æ®é›†å¹¶æå–æ ·æœ¬
        print("\nğŸ“‚ åŠ è½½æ•°æ®é›†...")
        self.load_and_extract_datasets()
        
        if not self.samples:
            print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®é›†ï¼")
            return
        
        # æ˜¾ç¤ºåŠ è½½çš„æ•°æ®é›†ä¿¡æ¯
        print(f"\nğŸ“Š æˆåŠŸåŠ è½½ {len(self.samples)} ä¸ªæ•°æ®é›†:")
        for dataset_name, samples in self.samples.items():
            print(f"  - {dataset_name}: {len(samples)} ä¸ªæ ·æœ¬")
            
            # æ˜¾ç¤ºè¯¥æ•°æ®é›†å¯ç”¨çš„maskç±»å‹
            if samples:
                available_masks = samples[0].get('available_masks', {})
                mask_types = list(available_masks.keys())
                print(f"    å¯ç”¨maskç±»å‹: {mask_types}")
        
        # ä¸ºæ¯ä¸ªæ•°æ®é›†è¿è¡Œæ¨ç†
        print(f"\nğŸš€ å¼€å§‹æ¨ç†é˜¶æ®µ...")
        for dataset_name in self.samples.keys():
            try:
                self.run_inference_for_dataset(dataset_name)
            except Exception as e:
                print(f"âŒ å¤„ç†æ•°æ®é›† {dataset_name} æ—¶å‡ºé”™: {e}")
                continue
        
        print("\nâœ… æ‰€æœ‰æ¨ç†å®Œæˆï¼")
    
    def calculate_metrics_for_dataset(self, dataset_name):
        """ä¸ºå•ä¸ªæ•°æ®é›†è®¡ç®—æŒ‡æ ‡"""
        if dataset_name not in self.predictions or dataset_name not in self.texts:
            return {}
        
        references = self.texts[dataset_name]
        predictions = self.predictions[dataset_name]
        
        ref_format = [[ref] for ref in references]
        
        dataset_results = {}
        
        for model_name, preds in predictions.items():
            try:
                bleu_scores = self.metrics.compute_bleu(preds, ref_format)
                meteor_score = self.metrics.compute_meteor(preds, ref_format)
                rouge_score = self.metrics.compute_rouge_l(preds, ref_format)
                cider_score = self.metrics.compute_cider(preds, ref_format)
                
                dataset_results[model_name] = {
                    'BLEU-1': bleu_scores['BLEU-1'],
                    'BLEU-2': bleu_scores['BLEU-2'],
                    'BLEU-3': bleu_scores['BLEU-3'],
                    'BLEU-4': bleu_scores['BLEU-4'],
                    'METEOR': meteor_score,
                    'ROUGE-L': rouge_score,
                    'CIDEr': cider_score
                }
                
            except Exception as e:
                print(f"âŒ è®¡ç®— {model_name} åœ¨ {dataset_name} ä¸Šçš„æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
                continue
        
        return dataset_results
    
    def calculate_all_metrics(self):
        """è®¡ç®—æ‰€æœ‰æ•°æ®é›†çš„æŒ‡æ ‡"""
        all_results = {}
        
        for dataset_name in self.predictions.keys():
            dataset_metrics = self.calculate_metrics_for_dataset(dataset_name)
            all_results[dataset_name] = dataset_metrics
        
        return all_results
    
    def print_results(self, all_results):
        """æ‰“å°å¯¹æ¯”è¡¨æ ¼æ ¼å¼çš„ç»“æœ"""
        print("\n" + "="*120)
        print("ğŸ“Š å¤šæ¨¡å‹å¯¹æ¯”è¯„ä¼°ç»“æœ")
        print("="*120)
        
        # æ‰“å°maskä½¿ç”¨é…ç½®
        print("ğŸ¯ æ¨¡å‹Maské…ç½®:")
        for model_name, dataset_configs in self.model_mask_config.items():
            print(f"  {model_name}:")
            for dataset_name, mask_type in dataset_configs.items():
                mask_info = mask_type if mask_type else "æ— mask(ä»…åŸå›¾)"
                print(f"    - {dataset_name}: {mask_info}")
        print("-" * 120)
        
        # è·å–æ‰€æœ‰æ•°æ®é›†åç§°
        dataset_names = list(all_results.keys())
        
        if not dataset_names:
            print("âŒ æ²¡æœ‰è¯„ä¼°ç»“æœå¯æ˜¾ç¤º")
            return
        
        # æ‰“å°è¡¨å¤´
        print(f"{'':15}", end="")
        for dataset_name in dataset_names:
            dataset_display = dataset_name.lower().replace('refcocoplus', 'refcoco').replace('visualgenome', 'visual_genome')
            print(f"{dataset_display:^50}", end="")
        print()
        
        print(f"{'æ¨¡å‹':<15}", end="")
        for _ in dataset_names:
            print(f"{'bleu-1':<10}{'bleu-2':<10}{'meteor':<10}{'rouge-l':<10}{'cider':<10}", end="")
        print()
        print("-" * (15 + 50 * len(dataset_names)))
        
        # è·å–æ‰€æœ‰æ¨¡å‹åç§°å¹¶æ’åº
        all_models = set()
        for dataset_results in all_results.values():
            all_models.update(dataset_results.keys())
        
        # æŒ‰é¡ºåºæ˜¾ç¤ºæ¨¡å‹
        model_order = ['blip', 'alphablip', 'kosmos2']
        model_order = [m for m in model_order if m in all_models]
        
        # æ·»åŠ å…¶ä»–æ¨¡å‹
        for model in sorted(all_models):
            if model not in model_order:
                model_order.append(model)
        
        # æ‰“å°æ¯ä¸ªæ¨¡å‹çš„ç»“æœ
        for model_name in model_order:
            print(f"{model_name:<15}", end="")
            
            for dataset_name in dataset_names:
                if (dataset_name in all_results and 
                    model_name in all_results[dataset_name]):
                    metrics = all_results[dataset_name][model_name]
                    
                    bleu_1 = metrics.get('BLEU-1', 0.0)
                    bleu_2 = metrics.get('BLEU-2', 0.0)
                    meteor = metrics.get('METEOR', 0.0)
                    rouge_l = metrics.get('ROUGE-L', 0.0)
                    cider = metrics.get('CIDEr', 0.0)
                    
                    print(f"{bleu_1:<10.3f}{bleu_2:<10.3f}{meteor:<10.3f}{rouge_l:<10.3f}{cider:<10.3f}", end="")
                else:
                    # å¦‚æœè¯¥æ¨¡å‹åœ¨è¯¥æ•°æ®é›†ä¸Šæ²¡æœ‰ç»“æœï¼Œæ˜¾ç¤ºç©ºå€¼
                    print(f"{'':10}{'':10}{'':10}{'':10}{'':10}", end="")
            print()
        
        print("="*120)
    
    def save_results(self, all_results, output_dir='results'):
        """ä¿å­˜æ‰€æœ‰ç»“æœ"""
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹é…ç½®ä¿¡æ¯
        config_info = {
            'model_mask_config': self.model_mask_config,
            'evaluation_time': str(pd.Timestamp.now()),
            'config_summary': {
                'max_length': getattr(self.config, 'max_length', 50),
                'num_beams': getattr(self.config, 'num_beams', 5),
                'max_samples_per_dataset': getattr(self.config, 'max_samples_per_dataset', None)
            }
        }
        
        with open(f'{output_dir}/evaluation_config.json', 'w') as f:
            json.dump(config_info, f, indent=2)
        
        for dataset_name in self.predictions.keys():
            dataset_dir = os.path.join(output_dir, dataset_name)
            os.makedirs(dataset_dir, exist_ok=True)
            
            detailed_results = []
            samples = self.samples[dataset_name]
            references = self.texts[dataset_name]
            predictions = self.predictions[dataset_name]
            
            for i, (sample, ref) in enumerate(zip(samples, references)):
                item = {
                    'id': i,
                    'original_index': sample['index'],
                    'sample_index': sample.get('sample_idx', i),
                    'dataset_name': sample['dataset_name'],
                    'reference': ref,
                }
                
                # æ·»åŠ æ¨¡å‹é¢„æµ‹ç»“æœå’Œä½¿ç”¨çš„maskä¿¡æ¯
                for model_name, preds in predictions.items():
                    if i < len(preds):
                        item[f'{model_name}_prediction'] = preds[i]
                        # è®°å½•è¯¥æ¨¡å‹ä½¿ç”¨çš„maskç±»å‹
                        mask_type = self.model_mask_config.get(model_name, {}).get(dataset_name, None)
                        item[f'{model_name}_mask_type'] = mask_type if mask_type else "no_mask"
                    else:
                        item[f'{model_name}_prediction'] = ""
                        item[f'{model_name}_mask_type'] = "unknown"
                
                # æ·»åŠ åŸå§‹æ ·æœ¬çš„å…¶ä»–ä¿¡æ¯
                original_sample = sample.get('original_sample', {})
                if 'ref_id' in original_sample:
                    item['ref_id'] = original_sample['ref_id']
                if 'category_id' in original_sample:
                    item['category_id'] = original_sample['category_id']
                if 'normalized_bbox' in original_sample:
                    item['normalized_bbox'] = original_sample['normalized_bbox']
                
                detailed_results.append(item)
            
            with open(f'{dataset_dir}/predictions.json', 'w', encoding='utf-8') as f:
                json.dump(detailed_results, f, ensure_ascii=False, indent=2)
            
            if dataset_name in all_results:
                with open(f'{dataset_dir}/metrics.json', 'w') as f:
                    json.dump(all_results[dataset_name], f, indent=2)
        
        with open(f'{output_dir}/all_metrics.json', 'w') as f:
            json.dump(all_results, f, indent=2)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_dir}/")
        for dataset_name in self.predictions.keys():
            sample_count = len(self.samples[dataset_name])
            print(f"  - {dataset_name}: {sample_count} ä¸ªæ ·æœ¬çš„ç»“æœ")
        print(f"  - è¯„ä¼°é…ç½®å·²ä¿å­˜åˆ°: evaluation_config.json")


def main():
    """ä¸»å‡½æ•°"""
    
    print("=" * 80)
    print("ğŸš€ å¤šæ¨¡å‹å¯¹æ¯”è¯„ä¼°ç¨‹åº")
    print("=" * 80)
    
    # é…ç½®ç±» - æ”¯æŒå¤šä¸ªæ¨¡å‹
    class Config:
        # åŸºç¡€æ¨¡å‹é…ç½®
        base_model = "Salesforce/blip-image-captioning-base"  # åŸºç¡€BLIPæ¨¡å‹
        checkpoint_path = "/home/chenzc/cvd/model_blip/outputs/alpha_blip_training/checkpoints/best_model.pt"  # AlphaBlipæ£€æŸ¥ç‚¹è·¯å¾„
        device = None  # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡ï¼Œæˆ–æŒ‡å®š "cuda" / "cpu"
        max_length = 50   # ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦
        num_beams = 5     # beam searchçš„beamæ•°é‡
        
        # æ˜¯å¦ä½¿ç”¨Kosmos2æ¨¡å‹
        use_kosmos2 = True  # è®¾ä¸ºTrueä»¥å¯ç”¨Kosmos2æ¨¡å‹
        
        # æ•°æ®é›†é‡‡æ ·é…ç½®
        max_samples_per_dataset = 100  # æ¯ä¸ªæ•°æ®é›†æœ€å¤§æ ·æœ¬æ•°ï¼Œè®¾ä¸ºNoneåˆ™ä½¿ç”¨å…¨éƒ¨æ ·æœ¬
        
        # VisualGenome æ•°æ®é›†é…ç½®
        vg_region_descriptions_file = "/home/chenzc/cvd/model_blip/data/data/visual_genome/VG_val_3000/region_descriptions.json"
        vg_image_data_file = "/home/chenzc/cvd/model_blip/data/data/visual_genome/VG_val_3000/image_data.json"
        vg_images_dir = "/home/chenzc/cvd/model_blip/data/data/visual_genome/VG_100K_all"
        
        # RefCOCO+ æ•°æ®é›†é…ç½®
        refs_file = "/home/chenzc/cvd/model_blip/data/data/COCO/refcoco+/refs(unc).p"
        instances_file = "/home/chenzc/cvd/model_blip/data/data/COCO/refcoco+/instances.json"
        images_dir = "/home/chenzc/cvd/model_blip/data/data/COCO/train2014"
        
        # æ¨¡å‹maské…ç½® - åœ¨è¿™é‡Œå®šä¹‰æ¯ä¸ªæ¨¡å‹ä½¿ç”¨ä»€ä¹ˆmask
        model_mask_config = {
            'blip': {
                'VisualGenome': None,  # BLIPä¸ä½¿ç”¨maskï¼Œåªç”¨åŸå›¾
                'RefCOCOPlus': None
            },
            'alphablip': {
                'VisualGenome': 'ellipse_mask',  # AlphaBlipåœ¨VGä¸Šä½¿ç”¨ellipse_mask
                'RefCOCOPlus': 'gray_mask'       # AlphaBlipåœ¨RefCOCO+ä¸Šä½¿ç”¨gray_mask
            },
            # å¦‚æœå¯ç”¨Kosmos2ï¼Œå¯ä»¥åœ¨è¿™é‡Œé…ç½®
            'kosmos2': {
                'VisualGenome': None,   # Kosmos2ä½¿ç”¨bboxä¿¡æ¯ï¼Œä¸éœ€è¦mask
                'RefCOCOPlus': None
            }
        }

    config = Config()
    
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"  - åŸºç¡€æ¨¡å‹: {config.base_model}")
    print(f"  - AlphaBlipæ£€æŸ¥ç‚¹: {config.checkpoint_path}")
    print(f"  - ä½¿ç”¨Kosmos2: {config.use_kosmos2}")
    print(f"  - æ¯ä¸ªæ•°æ®é›†æœ€å¤§æ ·æœ¬æ•°: {config.max_samples_per_dataset}")
    print(f"  - æœ€å¤§ç”Ÿæˆé•¿åº¦: {config.max_length}")
    print(f"  - Beamæ•°é‡: {config.num_beams}")
    
    print(f"\nğŸ¯ æ¨¡å‹Maské…ç½®:")
    for model_name, dataset_configs in config.model_mask_config.items():
        print(f"  {model_name}:")
        for dataset_name, mask_type in dataset_configs.items():
            mask_info = mask_type if mask_type else "æ— mask(ä»…åŸå›¾)"
            print(f"    - {dataset_name}: {mask_info}")
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = ModelComparisionEvaluator(config)
    
    try:
        # è¿è¡Œè¯„ä¼°
        evaluator.run_evaluation()
        
        # è®¡ç®—æŒ‡æ ‡
        print("\nğŸ“Š è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
        all_results = evaluator.calculate_all_metrics()
        
        # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
        evaluator.print_results(all_results)
        
        # ä¿å­˜ç»“æœ
        evaluator.save_results(all_results)
        
        print("\nğŸ‰ è¯„ä¼°å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()